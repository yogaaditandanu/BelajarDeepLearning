{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1UNrzJr+VFhy+/Q2wI7rv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogaaditandanu/BelajarDeepLearning/blob/main/Processing_Data_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBIKdwHYQpsk",
        "outputId": "38fbe475-5632-4d01-a68f-d810f75dc1ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zanE_rzsQwny",
        "outputId": "d3b4ed51-30c0-41dd-e1cd-ca299bb14154"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.12/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CASE FOLDING"
      ],
      "metadata": {
        "id": "0YcrkFx9Q7cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh teks\n",
        "teks_asli = \"Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\"\n",
        "# Mengubah teks menjadi lowercase\n",
        "teks_lowercase = teks_asli.lower()\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\", teks_asli)\n",
        "print(\"Teks setelah diubah menjadi lowercase:\", teks_lowercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_D1ConRQ2FI",
        "outputId": "c0b7ea3e-7697-45ae-8cc8-69ac44dba6d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\n",
            "Teks setelah diubah menjadi lowercase: ini adalah contoh teks yang akan dikonversi menjadi lowercase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removal Special Characters"
      ],
      "metadata": {
        "id": "vcCsYm2gRC5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menghapus angka dari teks\n",
        "def hapus_angka(teks):\n",
        "  teks_tanpa_angka = ''.join([char for char in teks if not char.isdigit()])\n",
        "  return teks_tanpa_angka\n",
        "# Contoh teks dengan angka\n",
        "teks_dengan_angka = \"Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\"\n",
        "# Memanggil fungsi untuk menghapus angka\n",
        "teks_tanpa_angka = hapus_angka(teks_dengan_angka)\n",
        "# Menampilkan hasil\n",
        "print(\"Teks dengan angka:\", teks_dengan_angka)\n",
        "print(\"Teks tanpa angka:\", teks_tanpa_angka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04xOpPnDRFca",
        "outputId": "652c2a08-2a53-4c29-ea88-ae7469ce03e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks dengan angka: Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\n",
            "Teks tanpa angka: Ini adalah contoh teks dengan angka  yang akan dihapus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def hapus_angka_tidak_relevan(teks):\n",
        "# Menggunakan regex untuk mengidentifikasi dan menghapus angka yang tidak relevan\n",
        "# Pola untuk mengenali angka yang harus dihapus, termasuk nomor rumah dan nomor telepon\n",
        "   pola_angka_tidak_relevan = r\"\\b(?:\\d{1,3}[-\\.\\s]?)?(?:\\d{3}[-\\.\\s]?)?\\d{4,}\\b\"\n",
        "   hasil = re.sub(pola_angka_tidak_relevan, \"\", teks)\n",
        "   return hasil.strip()\n",
        "# Contoh kalimat dengan angka\n",
        "kalimat = \"Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi 081234567890 untuk informasi lebih lanjut.\"\n",
        "\n",
        "# Memanggil fungsi untuk menghapus angka tidak relevan\n",
        "hasil_tanpa_angka = hapus_angka_tidak_relevan(kalimat)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Kalimat dengan angka:\", kalimat)\n",
        "print(\"Kalimat tanpa angka tidak relevan:\", hasil_tanpa_angka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXWHaTv4RMtc",
        "outputId": "acd906e8-ba47-43f6-b265-ceacac07ac91"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kalimat dengan angka: Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi 081234567890 untuk informasi lebih lanjut.\n",
            "Kalimat tanpa angka tidak relevan: Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi  untuk informasi lebih lanjut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Membuat set yang berisi semua tanda baca\n",
        "    punctuation_set = set(string.punctuation)\n",
        "\n",
        "    # Menghapus tanda baca dari teks\n",
        "    text_without_punctuation = ''.join(char for char in text if char not in punctuation_set)\n",
        "\n",
        "    return text_without_punctuation\n",
        "\n",
        "# Contoh teks dengan tanda baca\n",
        "teks_asli = \"Ini adalah contoh teks, dengan tanda baca! Contoh ini, digunakan? untuk demonstrasi.\"\n",
        "\n",
        "# Menghapus tanda baca dari teks\n",
        "teks_tanpa_tanda_baca = remove_punctuation(teks_asli)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\", teks_asli)\n",
        "print(\"Teks setelah menghapus tanda baca:\", teks_tanpa_tanda_baca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AveOsG4BRkUr",
        "outputId": "a4f7b58c-efb6-45a8-91f7-c1e66aa72754"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Ini adalah contoh teks, dengan tanda baca! Contoh ini, digunakan? untuk demonstrasi.\n",
            "Teks setelah menghapus tanda baca: Ini adalah contoh teks dengan tanda baca Contoh ini digunakan untuk demonstrasi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks = \"   Ini adalah contoh kalimat dengan spasi di awal dan akhir.    \"\n",
        "teks_setelah_strip = teks.strip()\n",
        "print(teks_setelah_strip)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yylEdtOoRllS",
        "outputId": "583c994c-9b19-4b1a-b514-b8127e4af595"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ini adalah contoh kalimat dengan spasi di awal dan akhir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks_dengan_whitespace = \"Ini adalah    contoh kalimat    dengan spasi    di dalamnya.\"\n",
        "teks_tanpa_whitespace = teks_dengan_whitespace.replace(\" \", \"\")\n",
        "print(teks_tanpa_whitespace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_hzISxnRpv1",
        "outputId": "f22b1afd-5014-475e-b96a-41237c98a8c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniadalahcontohkalimatdenganspasididalamnya.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopword Removal (Filtering)"
      ],
      "metadata": {
        "id": "B2cc71PhRySL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download korpus stopwords bahasa Indonesia dari NLTK jika belum terunduh\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')  # Untuk tokenisasi kata\n",
        "\n",
        "teks = \"Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\"\n",
        "\n",
        "# Tokenisasi teks menjadi kata-kata\n",
        "tokens_kata = word_tokenize(teks)\n",
        "\n",
        "# Ambil daftar stopwords bahasa Indonesia dari NLTK\n",
        "stopwords_indonesia = set(stopwords.words('indonesian'))\n",
        "\n",
        "# Filtering kata-kata dengan menghapus stopwords\n",
        "kata_penting = [kata for kata in tokens_kata if kata.lower() not in stopwords_indonesia]\n",
        "\n",
        "# Gabungkan kata-kata penting kembali menjadi teks\n",
        "teks_tanpa_stopwords = ' '.join(kata_penting)\n",
        "\n",
        "print(\"Teks asli:\", teks)\n",
        "print(\"Teks setelah filtering stopwords NLTK:\", teks_tanpa_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ6eEhJ5Ry06",
        "outputId": "3f0f132a-fc86-4147-a32f-a9666f9b8f01"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\n",
            "Teks setelah filtering stopwords NLTK: Perekonomian Indonesia pertumbuhan membanggakan .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Sastrawi library if not already installed\n",
        "!pip install Sastrawi\n",
        "\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Inisialisasi objek StopWordRemover dari Sastrawi\n",
        "factory = StopWordRemoverFactory()\n",
        "stopwords_sastrawi = factory.get_stop_words()\n",
        "\n",
        "teks = \"Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\"\n",
        "\n",
        "# Tokenisasi teks menjadi kata-kata\n",
        "tokens_kata = word_tokenize(teks)\n",
        "\n",
        "# Filtering kata-kata dengan menghapus stopwords Sastrawi\n",
        "kata_penting = [kata for kata in tokens_kata if kata.lower() not in stopwords_sastrawi]\n",
        "\n",
        "# Gabungkan kata-kata penting kembali menjadi teks\n",
        "teks_tanpa_stopwords = ' '.join(kata_penting)\n",
        "\n",
        "print(\"Teks asli:\", teks)\n",
        "print(\"Teks setelah filtering stopwords Sastrawi:\", teks_tanpa_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIPkQZyAR-I2",
        "outputId": "7c1941d4-311d-47fd-fd80-0729105c6513"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Teks asli: Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\n",
            "Teks setelah filtering stopwords Sastrawi: Perekonomian Indonesia sedang pertumbuhan membanggakan .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenisasi"
      ],
      "metadata": {
        "id": "ZaVaTx94SZjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Ini adalah contoh tokenisasi kata dalam pemrosesan teks.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkHe8eEKSCLb",
        "outputId": "6900987f-b7ea-423f-e1c8-e6d54a6d05c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini', 'adalah', 'contoh', 'tokenisasi', 'kata', 'dalam', 'pemrosesan', 'teks', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"Ini adalah contoh tokenisasi kalimat. Apakah ini kalimat kedua? Ya, ini kalimat ketiga!\"\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fZIfR3CSY1Y",
        "outputId": "50ea450e-b880-4335-dddc-9bb18b5245bd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini adalah contoh tokenisasi kalimat.', 'Apakah ini kalimat kedua?', 'Ya, ini kalimat ketiga!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "# Misalkan kita ingin memisahkan frasa berdasarkan tanda baca koma (,)\n",
        "text = \"Pemrosesan teks adalah cabang ilmu komputer yang berfokus pada pengolahan teks dan dokumen.\"\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "phrases = tokenizer.tokenize(text)\n",
        "print(phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyZhOALUSbAd",
        "outputId": "cacb8120-8781-4efe-93a1-ba98cda22f65"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pemrosesan', 'teks', 'adalah', 'cabang', 'ilmu', 'komputer', 'yang', 'berfokus', 'pada', 'pengolahan', 'teks', 'dan', 'dokumen', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh aturan tokenisasi khusus untuk tokenisasi kata dalam bahasa Indonesia\n",
        "import re\n",
        "\n",
        "text = \"Pertama, kita perlu menyiapkan bahan-bahan yang diperlukan.\"\n",
        "tokens = re.findall(r'\\w+|\\d+', text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBozsYMQShqL",
        "outputId": "f3d49bf4-724d-4eef-de9c-0e2c7f80cfb1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pertama', 'kita', 'perlu', 'menyiapkan', 'bahan', 'bahan', 'yang', 'diperlukan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Misalnya menggunakan spasi sebagai pemisah kata\n",
        "text = \"Ini adalah contoh tokenisasi berbasis model.\"\n",
        "tokens = text.split()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8GBkffESyVE",
        "outputId": "48f63eda-b14e-4cd2-b2b8-6bb4ae4acca3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini', 'adalah', 'contoh', 'tokenisasi', 'berbasis', 'model.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING"
      ],
      "metadata": {
        "id": "BMIA3q8XTF6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Inisialisasi stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Kata-kata asli\n",
        "words = [\"running\", \"runs\", \"runner\", \"ran\", \"easily\", \"fairness\", \"better\", \"best\", \"cats\", \"cacti\", \"geese\", \"rocks\", \"oxen\"]\n",
        "\n",
        "# Melakukan stemming pada setiap kata\n",
        "for word in words:\n",
        "  stemmed_word = stemmer.stem(word)\n",
        "  print(f\"Kata asli: {word}, Kata setelah stemming: {stemmed_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TzfPgG7S1-N",
        "outputId": "77ebee5e-2bc8-4d94-8e39-3e6a7faa82ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kata asli: running, Kata setelah stemming: run\n",
            "Kata asli: runs, Kata setelah stemming: run\n",
            "Kata asli: runner, Kata setelah stemming: runner\n",
            "Kata asli: ran, Kata setelah stemming: ran\n",
            "Kata asli: easily, Kata setelah stemming: easili\n",
            "Kata asli: fairness, Kata setelah stemming: fair\n",
            "Kata asli: better, Kata setelah stemming: better\n",
            "Kata asli: best, Kata setelah stemming: best\n",
            "Kata asli: cats, Kata setelah stemming: cat\n",
            "Kata asli: cacti, Kata setelah stemming: cacti\n",
            "Kata asli: geese, Kata setelah stemming: gees\n",
            "Kata asli: rocks, Kata setelah stemming: rock\n",
            "Kata asli: oxen, Kata setelah stemming: oxen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "ampOIrLpTXXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download wordnet jika belum di-download\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Inisialisasi lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Kata-kata asli\n",
        "words = [\"Run\", \"Cat\", \"Good\", \"Goose\", \"Rock\", \"City\", \"Big\", \"Happy\", \"Run\", \"Sleep\"]\n",
        "\n",
        "# Melakukan lematisasi pada setiap kata\n",
        "for word in words:\n",
        "    lemma_word = lemmatizer.lemmatize(word.lower())  # Mengonversi ke huruf kecil untuk memastikan pemrosesan yang konsisten\n",
        "    print(f\"Kata asli: {word}, Kata setelah lematisasi: {lemma_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuLmY9vHTRSa",
        "outputId": "4523391d-99b0-4ba3-eb7f-1f8cdf760b8a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kata asli: Run, Kata setelah lematisasi: run\n",
            "Kata asli: Cat, Kata setelah lematisasi: cat\n",
            "Kata asli: Good, Kata setelah lematisasi: good\n",
            "Kata asli: Goose, Kata setelah lematisasi: goose\n",
            "Kata asli: Rock, Kata setelah lematisasi: rock\n",
            "Kata asli: City, Kata setelah lematisasi: city\n",
            "Kata asli: Big, Kata setelah lematisasi: big\n",
            "Kata asli: Happy, Kata setelah lematisasi: happy\n",
            "Kata asli: Run, Kata setelah lematisasi: run\n",
            "Kata asli: Sleep, Kata setelah lematisasi: sleep\n"
          ]
        }
      ]
    }
  ]
}